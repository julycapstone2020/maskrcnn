{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mjSRBvQxc89"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pydicom\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# load MDI client library\n",
    "import mdai\n",
    "mdai.__version__\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath('./lesson3-data')\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'logs')\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    os.makedirs(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "##Install Matterport's Mask-RCNN model from github. (https://github.com/matterport/Mask_RCNN)\n",
    "\n",
    "!git clone https://github.com/matterport/Mask_RCNN.git\n",
    "os.chdir('Mask_RCNN')\n",
    "\n",
    "def imShow(path):\n",
    "  import cv2\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "\n",
    "  image = cv2.imread(path)\n",
    "  height, width = image.shape[:2]\n",
    "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(18, 10)\n",
    "  plt.axis(\"off\")\n",
    "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
    "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()\n",
    "    \n",
    "# Import Mask RCNN\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "## Create an mdai client\n",
    "mdai_client = mdai.Client(domain='public.md.ai', access_token=\"54588a008e5f0e39c69e294bbc1dbe8f\")\n",
    "p = mdai_client.project('LxR6zdR2', path='./lesson3-data')\n",
    "# this maps label ids to class ids\n",
    "labels_dict = {'L_ylR0L8':0, # background \n",
    "               'L_DlqEAl':1, # lung opacity \n",
    "              }\n",
    "\n",
    "print(labels_dict)\n",
    "p.set_labels_dict(labels_dict)\n",
    "p.show_label_groups()\n",
    "p.show_datasets()\n",
    "dataset = p.get_dataset_by_id('D_ao3XWQ')\n",
    "dataset.prepare()\n",
    "dataset.show_classes()\n",
    "anns = dataset.get_annotations()\n",
    "## Train / test split\n",
    "train_dataset, valid_dataset = mdai.common_utils.train_test_split(dataset)\n",
    "anns = dataset.get_annotations(labels_dict.keys(), verbose=True)\n",
    "\n",
    "\n",
    "# These parameters have been changed to reduce run-time per epoch at the expense \n",
    "# of training performance\n",
    "\n",
    "\n",
    "class DetectorConfig(Config):\n",
    "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    Overrides values in the base Config class.\n",
    "    \"\"\"\n",
    "    NAME = 'pneumonia'\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 16 # on aws, use 16\n",
    "    BACKBONE = 'resnet50'\n",
    "    NUM_CLASSES = 2  # background + 1 pneumonia classes\n",
    "    IMAGE_MIN_DIM = 64\n",
    "    IMAGE_MAX_DIM = 64\n",
    "    #RPN_ANCHOR_SCALES = (32, 64)\n",
    "    TRAIN_ROIS_PER_IMAGE = 16\n",
    "    MAX_GT_INSTANCES = 3\n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    DETECTION_NMS_THRESHOLD = 0.1\n",
    "    POST_NMS_ROIS_TRAINING = 200\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 16\n",
    "    STEPS_PER_EPOCH = 100 \n",
    "    TOP_DOWN_PYRAMID_SIZE = 32\n",
    "     \n",
    "config = DetectorConfig()\n",
    "config.display()\n",
    "\n",
    "\n",
    "class DetectorDataset(utils.Dataset):\n",
    "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, source_name, dataset, orig_height, orig_width):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        # add classes \n",
    "        for k, v in dataset.classes_dict.items():\n",
    "            if v['class_id'] is not 0: \n",
    "                self.add_class(source_name, v['class_id'], v['class_text'])\n",
    "\n",
    "        # add images \n",
    "        img_ids = dataset.get_image_ids()\n",
    "        imgs_anns_dict = dataset.imgs_anns_dict\n",
    "        \n",
    "        #########################################################\n",
    "        # WARNING: Using only the first 1000 images to reduce \n",
    "        #          run-time for demonstration only \n",
    "        # To run all images, do: for i, fp in enumerate(img_ids):\n",
    "        #########################################################\n",
    "        for i, fp in enumerate(img_ids[:1000]):\n",
    "            annotations = imgs_anns_dict[fp]\n",
    "            self.add_image(source_name, image_id=i, path=fp, \n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "            \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info['path']\n",
    "        ds = pydicom.read_file(\n",
    "            fp)\n",
    "        image = ds.pixel_array\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            assert(dataset.label_id_to_class_id(a['labelId']) == 0)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                if a['data'] is not None:\n",
    "                    x = int(a['data']['x'])\n",
    "                    y = int(a['data']['y'])\n",
    "                    w = int(a['data']['width'])\n",
    "                    h = int(a['data']['height'])\n",
    "                    mask_instance = mask[:, :, i].copy()\n",
    "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
    "                    mask[:, :, i] = mask_instance\n",
    "                    class_ids[i] = dataset.label_id_to_class_id(a['labelId'])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "    \n",
    "    \n",
    "# Training dataset\n",
    "source_name = 'pneumonia'\n",
    "dataset_train = DetectorDataset(source_name, train_dataset, 1024, 1024)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = DetectorDataset(source_name, valid_dataset, 1024, 1024)\n",
    "dataset_val.prepare()\n",
    "\n",
    "##Display a few images\n",
    "\n",
    "# Load and display random samples\n",
    "image_id = 22 #random.choice(dataset_train.image_ids)\n",
    "image = dataset_train.load_image(image_id)\n",
    "#image = dataset_train.load_image(78)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "masked = np.zeros(image.shape[:2])\n",
    "for i in range(mask.shape[2]):\n",
    "    masked += image[:, :, 0] * mask[:, :, i]\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=MODEL_DIR)\n",
    "model.keras_model.metrics_tensors = []\n",
    "\n",
    "augmentation = iaa.SomeOf((0, 1), [\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    ),\n",
    "    iaa.Multiply((0.9, 1.1))\n",
    "])\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# Train Mask-RCNN Model \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=NUM_EPOCHS, \n",
    "            #augmentation=augmentation, # uncomment to enable augmentation\n",
    "            layers='all')\n",
    "\n",
    "# select trained model \n",
    "dir_names = next(os.walk(model.model_dir))[1]\n",
    "key = config.NAME.lower()\n",
    "dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
    "dir_names = sorted(dir_names)\n",
    "\n",
    "if not dir_names:\n",
    "    import errno\n",
    "    raise FileNotFoundError(\n",
    "        errno.ENOENT,\n",
    "        \"Could not find model directory under {}\".format(self.model_dir))\n",
    "    \n",
    "fps = []\n",
    "# Pick last directory\n",
    "for d in dir_names: \n",
    "    dir_name = os.path.join(model.model_dir, d)\n",
    "    # Find the last checkpoint\n",
    "    checkpoints = next(os.walk(dir_name))[2]\n",
    "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
    "    checkpoints = sorted(checkpoints)\n",
    "    if not checkpoints:\n",
    "        print('No weight files in {}'.format(dir_name))\n",
    "    else: \n",
    "      \n",
    "      checkpoint = os.path.join(dir_name, checkpoints[-1])\n",
    "      fps.append(checkpoint)\n",
    "\n",
    "model_path = sorted(fps)[-1]\n",
    "print('Found model {}'.format(model_path))\n",
    "\n",
    "class InferenceConfig(DetectorConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "def show_randoms(dataset):\n",
    "    fig = plt.figure(figsize=(10,20))\n",
    "\n",
    "    num_imgs = 12\n",
    "    for i in range(num_imgs):\n",
    "\n",
    "        image_id = random.choice(dataset.image_ids)\n",
    "        original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset, inference_config, \n",
    "                                   image_id, use_mini_mask=False)\n",
    "     \n",
    "        plt.subplot(num_imgs, 2, 2*i + 1)\n",
    "        visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                    dataset.class_names,\n",
    "                                    colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
    "        plt.title('Ground Truth')\n",
    "        \n",
    "        plt.subplot(num_imgs, 2, 2*i + 2)\n",
    "        \n",
    "        # turn off verbose if you don't want debug messages \n",
    "        results = model.detect([original_image],verbose=1)\n",
    "        r = results[0]\n",
    "        visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                    dataset.class_names, r['scores'], \n",
    "                                    colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])\n",
    "        plt.title('Prediction')\n",
    "        \n",
    "def get_colors_for_class_ids(class_ids):\n",
    "    colors = []\n",
    "    for class_id in class_ids:\n",
    "        if class_id == 1:\n",
    "            colors.append((.941, .204, .204))\n",
    "    return colors\n",
    "\n",
    "\n",
    "show_randoms(dataset_val)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "maskRCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
